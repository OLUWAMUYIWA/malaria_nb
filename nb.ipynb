{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "# conda create -n env1 python=3.9 matplotlib pickle-mixin python-csv numpy scikit-learn scikit-image scipy\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Useful Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def read_images(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    num1 = 32\n",
    "    num2 = 32\n",
    "    for file_name in os.listdir(path):\n",
    "        file_path = path + '/' + file_name\n",
    "        for img_name in os.listdir(file_path):\n",
    "            if not img_name.startswith('.'):\n",
    "                if img_name.endswith('.png'):\n",
    "                    img = cv2.imread(file_path + '/' + img_name)\n",
    "                    new_img = cv2.resize(img, (num2, num1))\n",
    "                    images.append(new_img)\n",
    "                    if file_name == 'Parasite':\n",
    "                        label = 0\n",
    "                    else:\n",
    "                        label = 1\n",
    "                    labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def write_csv(file, a1, a2, a3, a4, a5, a6, a7, name):\n",
    "    with open(file, mode='w') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(name)\n",
    "        for i in range(20):\n",
    "            if a2[i] == None:\n",
    "                a2[i] = 'None'\n",
    "            if a4[i] == None:\n",
    "                a4[i] = 'None'\n",
    "            csv_writer.writerow([a1[i], a2[i], a3[i], a4[i], a5[i], a6[i], a7[i]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save / Load Extracted Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def save_feature(feature, name):\n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open('cache/' + name + '.pkl', 'wb') as fp:\n",
    "        pickle.dump(csr_matrix(feature), fp)\n",
    "    \n",
    "    print(f'Feature saved with name cache/{name}.pkl')\n",
    "\n",
    "def load_feature(feature_name):\n",
    "    return pickle.load(open(feature_name, 'rb')).A"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save / Load Trained Model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def save_model(model):\n",
    "    filename = input('Enter model file name:')\n",
    "    pickle.dump(model, open('models/'+filename + '.pkl', 'wb'))\n",
    "    print(f'Successfully saved model in models/{filename}.pkl')\n",
    "\n",
    "def load_model(model_name):\n",
    "    return pickle.load(open(model_name, 'rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Flatten Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def flatten(images, color=cv2.COLOR_RGB2GRAY, name='flattened', save=False):\n",
    "    \"\"\"\n",
    "    color: default RGB2GRAY, if None is passed then color is used as it is.\n",
    "    \"\"\"\n",
    "    color_images = []\n",
    "    if color is not None:\n",
    "        for img in images:\n",
    "            color_images.append(cv2.cvtColor(img, color))\n",
    "    else:\n",
    "        color_images = images\n",
    "    \n",
    "    count = len(color_images)\n",
    "    \n",
    "    result = np.array(color_images).reshape(count, -1)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Color Histogram"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def color_histogram(images, name='color_hist', save=False):\n",
    "    histograms = []\n",
    "    for img in images:\n",
    "        histograms.append(cv2.calcHist([img], [0, 1, 2],None, [8, 8, 8], [0, 256, 0, 256, 0, 256]).flatten())\n",
    "    \n",
    "    result = np.array(histograms)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SURF Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def surf(images, name='surf', save=False):\n",
    "    # SURF descriptor for 1 image\n",
    "    def get_image_surf(image, vector_size=4):\n",
    "        alg = cv2.xfeatures2d.SURF_create()\n",
    "        kps = alg.detect(image, None)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "            \n",
    "        return dsc\n",
    "    \n",
    "    # SURF descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_surf(img)\n",
    "        features.append(dsc)\n",
    "    \n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def surf_kp(image):\n",
    "    alg = cv2.xfeatures2d.SURF_create()\n",
    "    kps = alg.detect(image, None)\n",
    "    kps = sorted(kps, key=lambda x: -x.response)[:4]\n",
    "\n",
    "    # Making descriptor of same size\n",
    "    # Descriptor vector size is 64\n",
    "    needed_size = (15 * 64)\n",
    "    if len(kps) == 0:\n",
    "        dsc = np.zeros(needed_size)\n",
    "    else:\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    return kps"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KAZE Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def kaze(images, name='kaze', save=False):\n",
    "    # KAZE descriptor for 1 image\n",
    "    def get_image_kaze(image, vector_size=32):\n",
    "        alg = cv2.KAZE_create()\n",
    "        kps = alg.detect(image)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        \n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "        return dsc\n",
    "    \n",
    "    # KAZE descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_kaze(img)\n",
    "        features.append(dsc)\n",
    "    \n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HOG Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def hog(images, name='hog', save=False):\n",
    "    result = np.array([hog(img, block_norm='L2') for img in images])\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SIFT Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sift(images, name='sift', save=False):\n",
    "    # SIFT descriptor for 1 image\n",
    "    def get_image_sift(image, vector_size=15):\n",
    "        alg = cv2.xfeatures2d.SIFT_create()\n",
    "        kps = alg.detect(image, None)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 128\n",
    "        needed_size = (vector_size * 128)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "            \n",
    "        return dsc\n",
    "    \n",
    "    # SIFT descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_sift(img)\n",
    "        features.append(dsc)\n",
    "\n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sift_kp(image):\n",
    "    alg = cv2.xfeatures2d.SIFT_create()\n",
    "    kps = alg.detect(image, None)\n",
    "    kps = sorted(kps, key=lambda x: -x.response)[:15]\n",
    "\n",
    "    # Making descriptor of same size\n",
    "    # Descriptor vector size is 128\n",
    "    needed_size = (15 * 128)\n",
    "    if len(kps) == 0:\n",
    "        dsc = np.zeros(needed_size)\n",
    "    else:\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    return kps"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LBP Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def lbp(images, name='lbp', save=False):\n",
    "    result = np.array([local_binary_pattern(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 10, 3).flatten() for img in images])\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine and Normalize Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def combine_features(features, horizontal=True):\n",
    "    \"\"\"\n",
    "    Array of features [f1, f2, f3] where each fi is a feature set \n",
    "    eg. f1=rgb_flat, f2=SIFT, etc.\n",
    "    \"\"\"\n",
    "    if horizontal:\n",
    "        return np.hstack(features)\n",
    "    else:\n",
    "        return np.vstack(features)\n",
    "\n",
    "\n",
    "def norm_features_min_max(train, test):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    norm_train = min_max_scaler.fit_transform(train)\n",
    "    norm_test = min_max_scaler.transform(test)\n",
    "    \n",
    "    return norm_train, norm_test\n",
    "\n",
    "\n",
    "def norm_features_zscore(train, test):\n",
    "    min_max_scaler = preprocessing.StandardScaler()\n",
    "    norm_train = min_max_scaler.fit_transform(train)\n",
    "    norm_test = min_max_scaler.transform(test)\n",
    "    \n",
    "    return norm_train, norm_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_model(train_x, train_y, validation=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    validation: (val_x, val_y) tupple for validation accuracy score.\n",
    "    \n",
    "    return: trained model\n",
    "    \"\"\"\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model_name = 'Naive Bayes'\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    if validation is not None:\n",
    "        y_hat = model.predict(validation[0])\n",
    "        acc = metrics.accuracy_score(validation[1], y_hat)\n",
    "        print(f\"Validation Accuracy in '{model_name}' = {acc}\")\n",
    "        cm = metrics.confusion_matrix(validation[1], y_hat)\n",
    "        print(cm)\n",
    "        recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "        precision = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "        f1 = 2*(precision*recall)/(precision+recall)\n",
    "        print(f\"Recall in '{model_name}' = {recall}\")\n",
    "        print(f\"Precision in '{model_name}' = {precision}\")\n",
    "        print(f\"F1 Score in '{model_name}' = {f1}\")\n",
    "               \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ROC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def roc(fpr, tpr, class_name, area):\n",
    "    figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    plt.plot(fpr,tpr)\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def combine_roc(test_y, prob):\n",
    "    n_classes = 7\n",
    "    name_arr = ['NB']\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = metrics.roc_curve(test_y, prob[:, i])\n",
    "        roc_auc[i] = metrics.roc_auc_score(test_y,  prob[:, i])\n",
    "\n",
    "    figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    colors = cycle(['darkorange'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color,\n",
    "                 label='ROC curve for ' + name_arr[i] + ' class (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues, figsize=(7,7), path=None, filename=None):\n",
    "        \"\"\"\n",
    "        cm: confusion matrix to be plotted.\n",
    "        classes: array of labels or class names.\n",
    "        title: title of the confusion matrix.\n",
    "        cmap: color of the plot matrix.\n",
    "        figsize: tupple (width, height) representiong size of the plot.\n",
    "        path: destination where the plot image will be saved.\n",
    "        filename: name to save the file with on the specified path. (if None, title is used)\n",
    "        \n",
    "        # Source: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "        \"\"\"\n",
    "        cm = cm.astype(np.int64)\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        fmt = 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        plt.grid(False)\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if path:\n",
    "            if filename is None:\n",
    "                plt.savefig(path + title + '.png')\n",
    "            else:\n",
    "                plt.savefig(path + filename + '.png')\n",
    "        plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def pca_projection(mat, name_arr):\n",
    "    plt.figure(figsize=(15,20))\n",
    "    for i, img in enumerate(mat, start=1):\n",
    "        plt.subplot(4, 2, i)\n",
    "        y = np.var(mat[i-1], axis=0)\n",
    "        x = list(range(1, len(y)+1))\n",
    "        plt.plot(x, y, '--o')\n",
    "        plt.ylabel('Variance')\n",
    "        plt.xlabel('Data Projected on Eigen Vector Number')\n",
    "        plt.xticks(x)\n",
    "        plt.title(name_arr[i-1])\n",
    "    plt.savefig('output/pca/subplot.jpg')\n",
    "    plt.show()\n",
    "\n",
    "def draw_key_points(image, kp):\n",
    "    img = cv2.drawKeypoints(image, kp, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    return img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RUN The Code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save and Load"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_data_x, full_data_y = read_images('cell_images')\n",
    "data_x, test_x, data_y, test_y = train_test_split(full_data_x, full_data_y, test_size=0.2)\n",
    "train_imgs, val_imgs, train_y, val_y = train_test_split(data_x, data_y, test_size=0.2)\n",
    "\n",
    "# save\n",
    "np.save('data/train_imgs.npy', train_imgs)\n",
    "np.save('data/train_y.npy', train_y)\n",
    "np.save('data/val_imgs.npy', val_imgs)\n",
    "np.save('data/val_y.npy', val_y)\n",
    "\n",
    "np.save('data/data_x.npy', data_x)\n",
    "np.save('data/data_y.npy', data_y)\n",
    "np.save('data/test_x.npy', test_x)\n",
    "np.save('data/test_y.npy', test_y)\n",
    "\n",
    "\n",
    "# load\n",
    "train_imgs = np.load('data/train_imgs.npy')\n",
    "train_y = np.load('data/train_y.npy')\n",
    "val_imgs = np.load('data/val_imgs.npy')\n",
    "val_y = np.load('data/val_y.npy')\n",
    "\n",
    "data_x = np.load('data/data_x.npy')\n",
    "data_y = np.load('data/data_y.npy')\n",
    "test_x = np.load('data/test_x.npy')\n",
    "test_y = np.load('data/test_y.npy')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "infected_img = train_imgs[train_y == 0][8]\n",
    "uninfected_img = train_imgs[train_y == 1][4]\n",
    "classes = []\n",
    "classes.append(infected_img)\n",
    "classes.append(uninfected_img)\n",
    "class_label= []\n",
    "class_label.append('infected image')\n",
    "class_label.append('uninfected image')\n",
    "\n",
    "vis_img = np.zeros((2, 32, 32))\n",
    "lbp_img = np.zeros((2, 32, 32))\n",
    "sift = np.zeros((2, 32, 32, 3), dtype='uint8')\n",
    "surf = np.zeros((2, 32, 32, 3), dtype='uint8')\n",
    "\n",
    "for i in range(2):\n",
    "    temp1, vis_img[i] = hog(classes[i], block_norm='L2', visualize=True)\n",
    "    lbp_img[i] = local_binary_pattern(cv2.cvtColor(classes[i], cv2.COLOR_RGB2GRAY), 10, 3)\n",
    "    sift[i] = draw_key_points(cv2.cvtColor(classes[i], cv2.COLOR_RGB2GRAY), sift_kp(classes[i]))\n",
    "    surf[i] = draw_key_points(cv2.cvtColor(classes[i], cv2.COLOR_RGB2GRAY), surf_kp(classes[i]))\n",
    "\n",
    "\n",
    "data_vis = []\n",
    "for i in range(len(classes)):\n",
    "    data_vis.append(classes[i])\n",
    "for i in range(len(classes)):\n",
    "    data_vis.append(vis_img[i])\n",
    "for i in range(len(classes)):\n",
    "    data_vis.append(lbp_img[i])\n",
    "for i in range(len(classes)):\n",
    "    data_vis.append(sift[i])\n",
    "for i in range(len(classes)):\n",
    "    data_vis.append(surf[i])\n",
    "\n",
    "img_name_arr = []\n",
    "for i in range(len(classes)):\n",
    "    img_name_arr.append(class_label[i])\n",
    "for i in range(len(classes)):\n",
    "    img_name_arr.append('HOG')\n",
    "for i in range(len(classes)):\n",
    "    img_name_arr.append('LBP')\n",
    "for i in range(len(classes)):\n",
    "    img_name_arr.append('SIFT')\n",
    "for i in range(len(classes)):\n",
    "    img_name_arr.append('SURF')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4,10))\n",
    "for i, img in enumerate(data_vis, start=1):\n",
    "    plt.subplot(5, 2, i)\n",
    "    plt.title(img_name_arr[i-1])\n",
    "    frame1 = plt.gca()\n",
    "    for tick in frame1.axes.get_xticklines():\n",
    "        tick.set_visible(False)\n",
    "    for tick in frame1.axes.get_yticklines():\n",
    "        tick.set_visible(False)\n",
    "    for xlabel_i in frame1.axes.get_xticklabels():\n",
    "        xlabel_i.set_visible(False)\n",
    "    for xlabel_i in frame1.axes.get_yticklabels():\n",
    "        xlabel_i.set_visible(False)\n",
    "    plt.imshow(data_vis[i-1], cmap='gray')\n",
    "plt.savefig('output/feature_visualization.png')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# HOG\n",
    "hog_train = hog(train_imgs, name='hog_train', save=True)\n",
    "hog_val = hog(val_imgs, name='hog_val', save=True)\n",
    "\n",
    "hog_train = load_feature('cache/hog_train.pkl')\n",
    "hog_val = load_feature('cache/hog_val.pkl')\n",
    "\n",
    "# LBP\n",
    "lbp_train = lbp(train_imgs, name='lbp_train', save=True)\n",
    "lbp_val = lbp(val_imgs, name='lbp_val', save=True)\n",
    "\n",
    "lbp_train = load_feature('cache/lbp_train.pkl')\n",
    "lbp_val = load_feature('cache/lbp_val.pkl')\n",
    "\n",
    "# KAZE\n",
    "kaze_train = kaze(train_imgs, name='kaze_train', save=True)\n",
    "kaze_val = kaze(val_imgs, name='kaze_val', save=True)\n",
    "\n",
    "kaze_train = load_feature('cache/kaze_train.pkl')\n",
    "kaze_val = load_feature('cache/kaze_val.pkl')\n",
    "\n",
    "\n",
    "# SIFT\n",
    "sift_train = sift(train_imgs, name='sift_train', save=True)\n",
    "sift_val = sift(val_imgs, name='sift_val', save=True)\n",
    "\n",
    "sift_train = load_feature('cache/sift_train.pkl')\n",
    "sift_val = load_feature('cache/sift_val.pkl')\n",
    "\n",
    "# SURF\n",
    "surf_train = surf(train_imgs, name='surf_train', save=True)\n",
    "surf_val = surf(val_imgs, name='surf_val', save=True)\n",
    "\n",
    "surf_train = load_feature('cache/surf_train.pkl')\n",
    "surf_val = load_feature('cache/surf_val.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Flatten images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# RGB\n",
    "flat_rgb_train = flatten(train_imgs, None, name='flat_rgb_train', save=True)\n",
    "flat_rgb_val = flatten(val_imgs, None, name='flat_rgb_val', save=True)\n",
    "\n",
    "flat_rgb_train = load_feature('cache/flat_rgb_train.pkl')\n",
    "flat_rgb_val = load_feature('cache/flat_rgb_val.pkl')\n",
    "\n",
    "# GRAYSCALE\n",
    "flat_gray_train = flatten(train_imgs, name='flat_gray_train', save=True)\n",
    "flat_gray_val = flatten(val_imgs, name='flat_gray_val', save=True)\n",
    "\n",
    "flat_gray_train = load_feature('cache/flat_gray_train.pkl')\n",
    "flat_gray_val = load_feature('cache/flat_gray_val.pkl')\n",
    "\n",
    "# Color Histogram\n",
    "hist_train = color_histogram(train_imgs, name='hist_train', save=True)\n",
    "hist_val = color_histogram(val_imgs, name='hist_val', save=True)\n",
    "\n",
    "hist_train = load_feature('cache/hist_train.pkl')\n",
    "hist_val = load_feature('cache/hist_val.pkl')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features Reduced by PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# HOG\n",
    "norm_hog_train, norm_hog_val = norm_features_zscore(hog_train, hog_val)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca_hog_train = pca.fit_transform(norm_hog_train)\n",
    "pca_hog_val = pca.transform(norm_hog_val)\n",
    "\n",
    "np.save('cache/pca_hog_train.npy', pca_hog_train)\n",
    "np.save('cache/pca_hog_val.npy', pca_hog_val)\n",
    "\n",
    "pca_hog_train = np.load('cache/pca_hog_train.npy')\n",
    "pca_hog_val = np.load('cache/pca_hog_val.npy')\n",
    "\n",
    "# LBP\n",
    "norm_lbp_train, norm_lbp_val = norm_features_zscore(lbp_train, lbp_val)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca_lbp_train = pca.fit_transform(norm_lbp_train)\n",
    "pca_lbp_val = pca.transform(norm_lbp_val)\n",
    "\n",
    "np.save('cache/pca_lbp_train.npy', pca_lbp_train)\n",
    "np.save('cache/pca_lbp_val.npy', pca_lbp_val)\n",
    "\n",
    "pca_lbp_train = np.load('cache/pca_lbp_train.npy')\n",
    "pca_lbp_val = np.load('cache/pca_lbp_val.npy')\n",
    "\n",
    "# KAZE\n",
    "norm_kaze_train, norm_kaze_val = norm_features_zscore(kaze_train, kaze_val)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca_kaze_train = pca.fit_transform(norm_kaze_train)\n",
    "pca_kaze_val = pca.transform(norm_kaze_val)\n",
    "\n",
    "np.save('cache/pca_kaze_train.npy', pca_kaze_train)\n",
    "np.save('cache/pca_kaze_val.npy', pca_kaze_val)\n",
    "\n",
    "pca_kaze_train = np.load('cache/pca_kaze_train.npy')\n",
    "pca_kaze_val = np.load('cache/pca_kaze_val.npy')\n",
    "\n",
    "# SIFT\n",
    "norm_sift_train, norm_sift_val = norm_features_zscore(sift_train, sift_val)\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca_sift_train = pca.fit_transform(norm_sift_train)\n",
    "pca_sift_val = pca.transform(norm_sift_val)\n",
    "\n",
    "np.save('cache/pca_sift_train.npy', pca_sift_train)\n",
    "np.save('cache/pca_sift_val.npy', pca_sift_val)\n",
    "\n",
    "pca_sift_train = np.load('cache/pca_sift_train.npy')\n",
    "pca_sift_val = np.load('cache/pca_sift_val.npy')\n",
    "\n",
    "# SURF\n",
    "norm_surf_train, norm_surf_val = norm_features_zscore(surf_train, surf_val)\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca_surf_train = pca.fit_transform(norm_surf_train)\n",
    "pca_surf_val = pca.transform(norm_surf_val)\n",
    "\n",
    "np.save('cache/pca_surf_train.npy', pca_surf_train)\n",
    "np.save('cache/pca_surf_val.npy', pca_surf_val)\n",
    "\n",
    "pca_surf_train = np.load('cache/pca_surf_train.npy')\n",
    "pca_surf_val = np.load('cache/pca_surf_val.npy')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Flattened Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# RGB\n",
    "norm_flat_rgb_train, norm_flat_rgb_val = norm_features_zscore(flat_rgb_train, flat_rgb_val)\n",
    "pca = PCA(n_components=10)\n",
    "pca_flat_rgb_train = pca.fit_transform(norm_flat_rgb_train)\n",
    "pca_flat_rgb_val = pca.transform(norm_flat_rgb_val)\n",
    "np.save('cache/pca_flat_rgb_train.npy', pca_flat_rgb_train)\n",
    "np.save('cache/pca_flat_rgb_val.npy', pca_flat_rgb_val)\n",
    "pca_flat_rgb_train = np.load('cache/pca_flat_rgb_train.npy')\n",
    "pca_flat_rgb_val = np.load('cache/pca_flat_rgb_val.npy')\n",
    "\n",
    "# GRAYSCALE\n",
    "norm_flat_gray_train, norm_flat_gray_val = norm_features_zscore(flat_gray_train, flat_gray_val)\n",
    "pca = PCA(n_components=6)\n",
    "pca_flat_gray_train = pca.fit_transform(norm_flat_gray_train)\n",
    "pca_flat_gray_val = pca.transform(norm_flat_gray_val)\n",
    "np.save('cache/pca_flat_gray_train.npy', pca_flat_gray_train)\n",
    "np.save('cache/pca_flat_gray_val.npy', pca_flat_gray_val)\n",
    "pca_flat_gray_train = np.load('cache/pca_flat_gray_train.npy')\n",
    "pca_flat_gray_val = np.load('cache/pca_flat_gray_val.npy')\n",
    "\n",
    "# Color Histogram\n",
    "norm_hist_train, norm_hist_val = norm_features_zscore(hist_train, hist_val)\n",
    "pca = PCA(n_components=10)\n",
    "pca_hist_train = pca.fit_transform(norm_hist_train)\n",
    "pca_hist_val = pca.transform(norm_hist_val)\n",
    "np.save('cache/pca_hist_train.npy', pca_hist_train)\n",
    "np.save('cache/pca_hist_val.npy', pca_hist_val)\n",
    "pca_hist_train = np.load('cache/pca_hist_train.npy')\n",
    "pca_hist_val = np.load('cache/pca_hist_val.npy')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pca_array = []\n",
    "pca_array.append(pca_hog_train)\n",
    "pca_array.append(pca_lbp_train)\n",
    "pca_array.append(pca_sift_train)\n",
    "pca_array.append(pca_surf_train)\n",
    "pca_array.append(pca_kaze_train)\n",
    "pca_array.append(pca_hist_train)\n",
    "pca_array.append(pca_flat_gray_train)\n",
    "pca_array.append(pca_flat_rgb_train)\n",
    "\n",
    "pca_projection(pca_array, ['HOG', 'LBP', 'SIFT', 'SURF', 'KAZE', 'Color Histogram', 'Flatten GRAY', 'Flatten RGB'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now Reduce Features by LDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# HOG Features\n",
    "lda = LDA()\n",
    "lda_hog_train = lda.fit_transform(norm_hog_train, train_y)\n",
    "lda_hog_val = lda.transform(norm_hog_val)\n",
    "np.save('cache/lda_hog_train.npy', lda_hog_train)\n",
    "np.save('cache/lda_hog_val.npy', lda_hog_val)\n",
    "lda_hog_train = np.load('cache/lda_hog_train.npy')\n",
    "lda_hog_val = np.load('cache/lda_hog_val.npy')\n",
    "\n",
    "# LBP Features\n",
    "lda = LDA()\n",
    "lda_lbp_train = lda.fit_transform(norm_lbp_train, train_y)\n",
    "lda_lbp_val = lda.transform(norm_lbp_val)\n",
    "np.save('cache/lda_lbp_train.npy', lda_lbp_train)\n",
    "np.save('cache/lda_lbp_val.npy', lda_lbp_val)\n",
    "lda_lbp_train = np.load('cache/lda_lbp_train.npy')\n",
    "lda_lbp_val = np.load('cache/lda_lbp_val.npy')\n",
    "\n",
    "# SIFT Features\n",
    "lda = LDA()\n",
    "lda_sift_train = lda.fit_transform(norm_sift_train, train_y)\n",
    "lda_sift_val = lda.transform(norm_sift_val)\n",
    "np.save('cache/lda_sift_train.npy', lda_sift_train)\n",
    "np.save('cache/lda_sift_val.npy', lda_sift_val)\n",
    "lda_sift_train = np.load('cache/lda_sift_train.npy')\n",
    "lda_sift_val = np.load('cache/lda_sift_val.npy')\n",
    "\n",
    "# Color Histogram\n",
    "lda = LDA()\n",
    "lda_hist_train = lda.fit_transform(norm_hist_train, train_y)\n",
    "lda_hist_val = lda.transform(norm_hist_val)\n",
    "np.save('cache/lda_hist_train.npy', lda_hist_train)\n",
    "np.save('cache/lda_hist_val.npy', lda_hist_val)\n",
    "lda_hist_train = np.load('cache/lda_hist_train.npy')\n",
    "lda_hist_val = np.load('cache/lda_hist_val.npy')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine Features (normal)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features_train = None\n",
    "features_val = None\n",
    "evs = []\n",
    "for ft, fv in zip([hog_train, hist_train, surf_train, flat_rgb_train, lbp_train, kaze_train, sift_train], \n",
    "                  [hog_val, hist_val, surf_val, flat_rgb_val, lbp_val, kaze_val, sift_val]):    \n",
    "    if features_train is None:\n",
    "        features_train = ft\n",
    "        features_val = fv\n",
    "    else:\n",
    "        features_train = combine_features([features_train, ft])\n",
    "        features_val = combine_features([features_val, fv])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine Features (PCA)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features_train = None\n",
    "features_val = None\n",
    "evs = []\n",
    "for ft, fv in zip([pca_hog_train, pca_lbp_train, pca_sift_train, pca_flat_rgb_train, pca_hist_train], \n",
    "                  [pca_hog_val, pca_lbp_val, pca_sift_val, pca_flat_rgb_val, pca_hist_val]):    \n",
    "    if features_train is None:\n",
    "        features_train = ft\n",
    "        features_val = fv\n",
    "    else:\n",
    "        features_train = combine_features([features_train, ft])\n",
    "        features_val = combine_features([features_val, fv])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine Features (LDA)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features_train_lda = None\n",
    "features_val_lda = None\n",
    "evs = []\n",
    "for ft, fv in zip([lda_hog_train, lda_hist_train, lda_lbp_train, lda_sift_train], \n",
    "                  [lda_hog_val, lda_hist_val, lda_lbp_val, lda_sift_val]):    \n",
    "    if features_train_lda is None:\n",
    "        features_train_lda = ft\n",
    "        features_val_lda = fv\n",
    "    else:\n",
    "        features_train_lda = combine_features([features_train_lda, ft])\n",
    "        features_val_lda = combine_features([features_val_lda, fv])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LDA on PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lda = LDA()\n",
    "lda_on_pca_train = lda.fit_transform(features_train, train_y)\n",
    "lda_on_pca_val = lda.transform(features_val)\n",
    "\n",
    "np.save('cache/lda_on_pca_train.npy', lda_on_pca_train)\n",
    "np.save('cache/lda_on_pca_val.npy', lda_on_pca_val)\n",
    "\n",
    "lda_on_pca_train = np.load('cache/lda_on_pca_train.npy')\n",
    "lda_on_pca_val = np.load('cache/lda_on_pca_val.npy')\n",
    "\n",
    "features_t = pca_hist_train\n",
    "features_v = pca_hist_val"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification using Gaussian NB"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nb_model_pca = train_model(features_train, train_y, validation=(features_val, val_y))\n",
    "\n",
    "prob_nb = nb_model_pca.predict_proba(features_val)\n",
    "prob_nb_0 = prob_nb[:,0].reshape(prob_nb.shape[0], 1)\n",
    "prob_nb_1 = prob_nb[:,1].reshape(prob_nb.shape[0], 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prob = np.concatenate((prob_nb_0), axis=1)\n",
    "combine_roc(val_y, prob)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prob = np.concatenate((prob_nb_1), axis=1)\n",
    "combine_roc(val_y, prob)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nb_model_lda = train_model(features_train_lda, train_y, validation=(features_val_lda, val_y))\n",
    "prob_nb_lda = nb_model_lda.predict_proba(features_val_lda)\n",
    "prob_nb_lda_0 = prob_nb_lda[:,0].reshape(prob_nb_lda.shape[0], 1)\n",
    "prob_nb_lda_1 = prob_nb_lda[:,1].reshape(prob_nb_lda.shape[0], 1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prob = np.concatenate((prob_nb_lda_0), axis=1)\n",
    "combine_roc(val_y, prob)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prob = np.concatenate((prob_nb_lda_1), axis=1)\n",
    "combine_roc(val_y, prob)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LDA on PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nb_model_LP = train_model(lda_on_pca_train, train_y, validation=(lda_on_pca_val, val_y))\n",
    "prob_LP = nb_model_LP.predict_proba(lda_on_pca_val)\n",
    "prob_LP_0 = prob_LP[:,0].reshape(prob_LP.shape[0], 1)\n",
    "prob_LP_1 = prob_LP[:,1].reshape(prob_LP.shape[0], 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prob = np.concatenate((prob_LP_0), axis=1)\n",
    "combine_roc(val_y, prob)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prob = np.concatenate((prob_LP_1), axis=1)\n",
    "combine_roc(val_y, prob)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "2b26696ba3931027e6c267be0913c8f249b8fd12cfae22ad198bc4f157a8df3e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}