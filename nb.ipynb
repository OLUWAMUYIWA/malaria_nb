{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from scipy.stats import randint\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import stats\n",
    "from lib import DataManipulationTools, MetricTools, PlotTools\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog, local_binary_pattern\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Useful Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def read_images(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    num1 = 32\n",
    "    num2 = 32\n",
    "    for file_name in os.listdir(path):\n",
    "        file_path = path + '/' + file_name\n",
    "        for img_name in os.listdir(file_path):\n",
    "            if not img_name.startswith('.'):\n",
    "                if img_name.endswith('.png'):\n",
    "                    img = cv2.imread(file_path + '/' + img_name)\n",
    "                    new_img = cv2.resize(img, (num2, num1))\n",
    "                    images.append(new_img)\n",
    "                    if file_name == 'Parasitized':\n",
    "                        label = 0\n",
    "                    else:\n",
    "                        label = 1\n",
    "                    labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def write_csv(file, a1, a2, a3, a4, a5, a6, a7, name):\n",
    "    with open(file, mode='w') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(name)\n",
    "        for i in range(20):\n",
    "            if a2[i] == None:\n",
    "                a2[i] = 'None'\n",
    "            if a4[i] == None:\n",
    "                a4[i] = 'None'\n",
    "            csv_writer.writerow([a1[i], a2[i], a3[i], a4[i], a5[i], a6[i], a7[i]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save / Load Extracted Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def save_feature(feature, name):\n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open('cache/' + name + '.pkl', 'wb') as fp:\n",
    "        pickle.dump(csr_matrix(feature), fp)\n",
    "    \n",
    "    print(f'Feature saved with name cache/{name}.pkl')\n",
    "\n",
    "def load_feature(feature_name):\n",
    "    return pickle.load(open(feature_name, 'rb')).A"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save / Load Trained Model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def save_model(model):\n",
    "    filename = input('Enter model file name:')\n",
    "    pickle.dump(model, open('models/'+filename + '.pkl', 'wb'))\n",
    "    print(f'Successfully saved model in models/{filename}.pkl')\n",
    "\n",
    "def load_model(model_name):\n",
    "    return pickle.load(open(model_name, 'rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Flatten Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def flatten(images, color=cv2.COLOR_RGB2GRAY, name='flattened', save=False):\n",
    "    \"\"\"\n",
    "    color: default RGB2GRAY, if None is passed then color is used as it is.\n",
    "    \"\"\"\n",
    "    color_images = []\n",
    "    if color is not None:\n",
    "        for img in images:\n",
    "            color_images.append(cv2.cvtColor(img, color))\n",
    "    else:\n",
    "        color_images = images\n",
    "    \n",
    "    count = len(color_images)\n",
    "    \n",
    "    result = np.array(color_images).reshape(count, -1)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Color Histogram"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def color_histogram(images, name='color_hist', save=False):\n",
    "    histograms = []\n",
    "    for img in images:\n",
    "        histograms.append(cv2.calcHist([img], [0, 1, 2],None, [8, 8, 8], [0, 256, 0, 256, 0, 256]).flatten())\n",
    "    \n",
    "    result = np.array(histograms)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SURF Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def surf(images, name='surf', save=False):\n",
    "    # SURF descriptor for 1 image\n",
    "    def get_image_surf(image, vector_size=4):\n",
    "        alg = cv2.xfeatures2d.SURF_create()\n",
    "        kps = alg.detect(image, None)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "            \n",
    "        return dsc\n",
    "    \n",
    "    # SURF descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_surf(img)\n",
    "        features.append(dsc)\n",
    "    \n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def surf_kp(image):\n",
    "    alg = cv2.xfeatures2d.SURF_create()\n",
    "    kps = alg.detect(image, None)\n",
    "    kps = sorted(kps, key=lambda x: -x.response)[:4]\n",
    "\n",
    "    # Making descriptor of same size\n",
    "    # Descriptor vector size is 64\n",
    "    needed_size = (15 * 64)\n",
    "    if len(kps) == 0:\n",
    "        dsc = np.zeros(needed_size)\n",
    "    else:\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    return kps"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KAZE Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def kaze(images, name='kaze', save=False):\n",
    "    # KAZE descriptor for 1 image\n",
    "    def get_image_kaze(image, vector_size=32):\n",
    "        alg = cv2.KAZE_create()\n",
    "        kps = alg.detect(image)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        \n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "        return dsc\n",
    "    \n",
    "    # KAZE descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_kaze(img)\n",
    "        features.append(dsc)\n",
    "    \n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HOG Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def hog(images, name='hog', save=False):\n",
    "    result = np.array([hog(img, block_norm='L2') for img in images])\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SIFT Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sift(images, name='sift', save=False):\n",
    "    # SIFT descriptor for 1 image\n",
    "    def get_image_sift(image, vector_size=15):\n",
    "        alg = cv2.xfeatures2d.SIFT_create()\n",
    "        kps = alg.detect(image, None)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        \n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 128\n",
    "        needed_size = (vector_size * 128)\n",
    "        if len(kps) == 0:\n",
    "            return np.zeros(needed_size)\n",
    "        \n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "            \n",
    "        return dsc\n",
    "    \n",
    "    # SIFT descriptor for all images\n",
    "    features = []\n",
    "    for i, img in enumerate(images):\n",
    "        dsc = get_image_sift(img)\n",
    "        features.append(dsc)\n",
    "\n",
    "    result = np.array(features)\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sift_kp(image):\n",
    "    alg = cv2.xfeatures2d.SIFT_create()\n",
    "    kps = alg.detect(image, None)\n",
    "    kps = sorted(kps, key=lambda x: -x.response)[:15]\n",
    "\n",
    "    # Making descriptor of same size\n",
    "    # Descriptor vector size is 128\n",
    "    needed_size = (15 * 128)\n",
    "    if len(kps) == 0:\n",
    "        dsc = np.zeros(needed_size)\n",
    "    else:\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less than 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    return kps"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LBP Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def lbp(images, name='lbp', save=False):\n",
    "    result = np.array([local_binary_pattern(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 10, 3).flatten() for img in images])\n",
    "    \n",
    "    if save:\n",
    "        save_feature(result, name)\n",
    "        \n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine and Normalize Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def combine_features(features, horizontal=True):\n",
    "    \"\"\"\n",
    "    Array of features [f1, f2, f3] where each fi is a feature set \n",
    "    eg. f1=rgb_flat, f2=SIFT, etc.\n",
    "    \"\"\"\n",
    "    if horizontal:\n",
    "        return np.hstack(features)\n",
    "    else:\n",
    "        return np.vstack(features)\n",
    "\n",
    "\n",
    "def norm_features_min_max(train, test):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    norm_train = min_max_scaler.fit_transform(train)\n",
    "    norm_test = min_max_scaler.transform(test)\n",
    "    \n",
    "    return norm_train, norm_test\n",
    "\n",
    "\n",
    "def norm_features_zscore(train, test):\n",
    "    min_max_scaler = preprocessing.StandardScaler()\n",
    "    norm_train = min_max_scaler.fit_transform(train)\n",
    "    norm_test = min_max_scaler.transform(test)\n",
    "    \n",
    "    return norm_train, norm_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_model(train_x, train_y, validation=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    validation: (val_x, val_y) tupple for validation accuracy score.\n",
    "    \n",
    "    return: trained model\n",
    "    \"\"\"\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model_name = 'Naive Bayes'\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    if validation is not None:\n",
    "        y_hat = model.predict(validation[0])\n",
    "        acc = metrics.accuracy_score(validation[1], y_hat)\n",
    "        print(f\"Validation Accuracy in '{model_name}' = {acc}\")\n",
    "        cm = metrics.confusion_matrix(validation[1], y_hat)\n",
    "        print(cm)\n",
    "        recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "        precision = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "        f1 = 2*(precision*recall)/(precision+recall)\n",
    "        print(f\"Recall in '{model_name}' = {recall}\")\n",
    "        print(f\"Precision in '{model_name}' = {precision}\")\n",
    "        print(f\"F1 Score in '{model_name}' = {f1}\")\n",
    "               \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}